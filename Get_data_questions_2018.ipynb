{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data for formatting\n",
    "\n",
    "- Needs to be extended to multiple wav files\n",
    "- Need to add filename somehow as a feature, to keep track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tgt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QUESTIONS']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reads in textgrid files\n",
    "#path= \"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/train_data/train50txtgrid/\"\n",
    "#path = \"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/test_data/test_txtgrds/\"\n",
    "path = \"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/sample_txtgrds/\"\n",
    "allFiles = os.listdir(path)\n",
    "onlyq_textgrds = []\n",
    "for item in allFiles:\n",
    "    fullpath = path+item\n",
    "    onlyq_textgrds.append(fullpath)\n",
    "\n",
    "\n",
    "checkGrid = onlyq_textgrds[2]\n",
    "#print(len(checkGrid))\n",
    "grid_obj= tgt.read_textgrid(checkGrid)\n",
    "grid_obj.get_tier_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/sample_txtgrds/p1_wh_01.TextGrid\n"
     ]
    }
   ],
   "source": [
    "print (onlyq_textgrds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "txtgrid_objs = []\n",
    "for item in onlyq_textgrds:\n",
    "    grid_obj = tgt.read_textgrid(item)\n",
    "    qTier = grid_obj.get_tier_by_name(\"QUESTIONS\")\n",
    "    txtgrid_objs.append(qTier)\n",
    "print(len(txtgrid_objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntervalTier(start_time=0.0, end_time=2.716734693877551, name=\"QUESTIONS\", objects=[Interval(0.0, 0.7460851797667405, \"#\"), Interval(0.7460851797667405, 1.7879367404150286, \"WH\"), Interval(1.7879367404150286, 2.716734693877551, \"#\")])\n"
     ]
    }
   ],
   "source": [
    "#qTier = grid_obj.get_tier_by_name(\"QUESTIONS\")\n",
    "#print (qTier)\n",
    "print(txtgrid_objs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[Interval(0.0, 1.0823466229334249, \"#\"), Interval(1.0823466229334249, 2.0406962405907834, \"WH\"), Interval(2.0406962405907834, 3.317551020408163, \"#\")], [Interval(0.0, 0.8332629485052394, \"#\"), Interval(0.8332629485052394, 2.3686782292597273, \"WH\"), Interval(2.3686782292597273, 3.2914285714285714, \"#\")], [Interval(0.0, 0.7460851797667405, \"#\"), Interval(0.7460851797667405, 1.7879367404150286, \"WH\"), Interval(1.7879367404150286, 2.716734693877551, \"#\")], [Interval(0.0, 0.6598890649941627, \"#\"), Interval(0.6598890649941627, 2.2340298845270525, \"Y/N\"), Interval(2.2340298845270525, 3.3436734693877552, \"#\")], [Interval(0.0, 0.5962363074307695, \"#\"), Interval(0.5962363074307695, 1.955592430225533, \"Y/N\"), Interval(1.955592430225533, 2.9779591836734696, \"#\")], [Interval(0.0, 0.5344228282730485, \"#\"), Interval(0.5344228282730485, 2.917725557010642, \"Y/N\"), Interval(2.917725557010642, 4.153469387755102, \"#\")]]\n"
     ]
    }
   ],
   "source": [
    "question_txtgrids = []\n",
    "for txtgrid in txtgrid_objs:\n",
    "    questions = txtgrid.annotations\n",
    "    question_txtgrids.append(questions)\n",
    "\n",
    "print(len(question_txtgrids))\n",
    "print (question_txtgrids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "question_tuples_list = []\n",
    "inter_list = []\n",
    "for item in question_txtgrids:\n",
    "    for i in range(len(item)):\n",
    "        ques = (item[i])\n",
    "        #print (ques)\n",
    "        if ques.text ==\"WH\" or ques.text== \"Y/N\":\n",
    "            #print(ques)\n",
    "            start = ques.start_time\n",
    "            end = ques.end_time\n",
    "            q_type = ques.text\n",
    "            entry = (start,end,q_type)\n",
    "            inter_list.append(entry)\n",
    "        else:\n",
    "            pass\n",
    "    question_tuples_list.append(inter_list)\n",
    "    inter_list = []\n",
    "    \n",
    "print(len(question_tuples_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0823466229334249, 2.0406962405907834, 'WH')]\n"
     ]
    }
   ],
   "source": [
    "print (question_tuples_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels = pd.read_csv(\"C:/Users/Rachel/Documents/Grad_Stuff/Dissertation/train_data/labels50_onlyqs.csv\")\n",
    "#train_labels = pd.read_csv(\"C:/Users/Rachel/Documents/Grad_Stuff/Dissertation/test_data/test_labels.txt\")\n",
    "train_labels = pd.read_csv('C:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/sample_labels.txt')\n",
    "train_labels = pd.DataFrame(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0)\n",
      "(1, 0)\n",
      "(1, 0)\n",
      "(0, 1)\n",
      "(0, 1)\n",
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "## let's count numbers of question IPUs!\n",
    "wh_count = 0\n",
    "yn_count = 0\n",
    "count = []\n",
    "inter = []\n",
    "for item in question_tuples_list:\n",
    "    for tup in item:\n",
    "        if tup[2] == \"WH\":\n",
    "            wh_count +=1\n",
    "        elif tup[2] == \"Y/N\":\n",
    "            yn_count += 1\n",
    "    entry = (wh_count, yn_count)\n",
    "    print (entry)\n",
    "    count.append(entry)\n",
    "    wh_count = 0\n",
    "    yn_count= 0\n",
    "    entry = ()\n",
    "#print (wh_count)\n",
    "#print (yn_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 0), (1, 0), (0, 1), (0, 1), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1072 + 808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English', 'English', 'English', 'English', 'English', 'English']\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for index, row in train_labels.iterrows():\n",
    "    label =(row[\"Language\"])\n",
    "    labels.append(label)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 0 0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "## get indexes\n",
    "idx_eng = []\n",
    "idx_man = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == \"English\":\n",
    "        idx_eng.append(i)\n",
    "    else:\n",
    "        idx_man.append(i)\n",
    "#print (idx_eng, idx_man)\n",
    "\n",
    "## \n",
    "eng_wh = 0\n",
    "eng_yn = 0\n",
    "man_wh = 0\n",
    "man_yn = 0\n",
    "for item in idx_eng:\n",
    "    tup = count[item]\n",
    "    wh = tup[0]\n",
    "    yn = tup[1]\n",
    "    eng_wh = eng_wh+wh\n",
    "    eng_yn = eng_yn+yn\n",
    "\n",
    "for item in idx_man:\n",
    "    tup = count[item]\n",
    "    wh = tup[0]\n",
    "    yn = tup[1]\n",
    "    man_wh = man_wh+wh\n",
    "    man_yn = man_yn+yn    \n",
    "print(eng_wh, eng_yn, man_wh, man_yn)\n",
    "total = eng_wh+eng_yn+man_wh+man_yn\n",
    "print(total)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "1433\n",
    "## test data\n",
    "1138\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "636+468, 696+480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "573-449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "427-381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(question_tuples_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out textgrids as txt files in the format below (only need to run once for train and once for test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a list of filenames for textgrids\n",
    "- for i in range len those filenames\n",
    "    - do stuff to question_tuples_list[i]\n",
    "    - make entry i, start_time, end_time, q_type:, q_type+\"\\n\"\n",
    "    - write entry to filename.txt\n",
    "- all files are written to txt files that are named what the audiofile is also called.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1_wh_01\n",
      "p1_wh_02\n",
      "p1_wh_03\n",
      "p1_yn_01\n",
      "p1_yn_02\n",
      "p1_yn_03\n"
     ]
    }
   ],
   "source": [
    "## train path\n",
    "path = \"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/sample_txtgrds/\"\n",
    "#path = \"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/train_data/train50txtgrid/\"\n",
    "\n",
    "## test path\n",
    "#path = \"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/test_data/test_txtgrds/\"\n",
    "allFiles = os.listdir(path)\n",
    "fnames = []\n",
    "for item in allFiles:\n",
    "    #fname = item[8:-9]#for train - has \"COMBINE_\"\n",
    "    fname = item[:-9]#for test - no COMBINE_\n",
    "    #print (fname)\n",
    "    fnames.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "p1_wh_01\n"
     ]
    }
   ],
   "source": [
    "print (len(fnames))\n",
    "print (fnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train outpath\n",
    "#outpath = \"C:/Users/Rachel/Documents/Grad_Stuff/Dissertation/question_data/format_train50txt/\"\n",
    "\n",
    "## test outpath\n",
    "#outpath = \"C:/Users/Rachel/Documents/Grad_Stuff/Dissertation/test_data/format_testtxt/\"\n",
    "\n",
    "#outpath = \"C:/Users/Rachel/Documents/Grad_Stuff/Dissertation/train_data/format_traintct_retry/\"\n",
    "outpath = \"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/format_sampletxt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have written to c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/format_sampletxt/p1_wh_01.txt\n",
      "You have written to c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/format_sampletxt/p1_wh_02.txt\n",
      "You have written to c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/format_sampletxt/p1_wh_03.txt\n",
      "You have written to c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/format_sampletxt/p1_yn_01.txt\n",
      "You have written to c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/format_sampletxt/p1_yn_02.txt\n",
      "You have written to c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/sample_data/format_sampletxt/p1_yn_03.txt\n"
     ]
    }
   ],
   "source": [
    "## write out to the correct format for segmenting F0\n",
    "for i in range(len(fnames)):\n",
    "    outName=outpath+fnames[i]+\".txt\"\n",
    "    outfile = open(outName,\"w\")\n",
    "    for j in range(len(question_tuples_list[i])):\n",
    "        start = question_tuples_list[i][j][0]\n",
    "        end = question_tuples_list[i][j][1]\n",
    "        qtype = question_tuples_list[i][j][2]\n",
    "        entry = (str(j)+\",\"+str(start)+\",\"+str(end)+\",\"+qtype+\":,\"+qtype+\"\\n\")\n",
    "        outfile.write(entry)\n",
    "    outfile.close()\n",
    "    print (\"You have written to \"+outName)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, q in enumerate(question_tuples_list):\n",
    "    if not q:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build feature vectors and label vectors - ledengre polynomial coeffs and probabilty features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_probs = pd.read_csv(\"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/degree_trials_data/final_probs_7deg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.read_csv(\"c:/Users/Rachel/Documents/Grad_Stuff/Dissertation/degree_trials_data/degree7_train_normspkrmean_legens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_probs = all_train_probs.rename(index=float, columns={\"English: WH\": \"EnglishWH\", \"English: Y/N\":\"EnglishYN\",\"Mandarin: WH\": \"MandarinWH\", \"Mandarin: Y/N\":'MandarinYN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_features = all_train_probs.drop([\"id\", \"language\",\"questions\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.concat([all_train_data, prob_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = []\n",
    "\n",
    "for i, row in all_train_data.iterrows():\n",
    "    leges = np.fromstring(row[\"legen_coefs\"][1:-1], dtype=float, sep=\",\")\n",
    "    coeffs.append(leges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[f'lg_{n}' for n in range(7)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####CHANGE DEGREE####range(x)where x is degree\n",
    "df_coeff = pd.DataFrame(coeffs, columns = [f'lg{n}' for n in range(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###rewrite this at some point, adding in these features just to get rid of them is stupid\n",
    "df_coeff[['language', 'questions']] = all_train_data[['language', 'questions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeff = pd.concat([df_coeff, prob_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### do not need?  Unless we are counting something?\n",
    "df_coeff_sorted = df_coeff.groupby(['language', 'questions'])\n",
    "\n",
    "df_coeff_sorted.groups\n",
    "\n",
    "df_coeff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame({'labels':df_coeff['language'] + \" \" + df_coeff['questions']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_coeff.drop(['language', 'questions'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And here, we change to language / question subsets, to see if we are doing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lang = df_coeff.drop(['language','questions'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_labels = df_coeff[\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ques = df_coeff.drop(['language','questions'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_labels = df_coeff['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add in f0 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make sure to deal with negative numbers?  or will this not work because of negative numbers?\n",
    "all_f0s = []\n",
    "for i, row in all_train_data.iterrows():\n",
    "    f0s = np.fromstring(row[\"f0final\"][1:-2], dtype=float, sep=\"\\n\")\n",
    "    #print (type((f0s)))\n",
    "    all_f0s.append(f0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_f0s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxf0s = []\n",
    "minf0s = []\n",
    "for listf0s in all_f0s:\n",
    "    high = max(listf0s)\n",
    "    low = min(listf0s)\n",
    "    maxf0s.append(high)\n",
    "    minf0s.append(low)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangef0s = []\n",
    "for i in range(len(maxf0s)):\n",
    "    diff = maxf0s[i] - minf0s[i]\n",
    "    rangef0s.append(diff)\n",
    "print (len(rangef0s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame({'maxf0s': maxf0s, 'minf0s':minf0s, 'rangef0s':rangef0s})\n",
    "df_lang = pd.DataFrame({'maxf0s': maxf0s, 'minf0s':minf0s, 'rangef0s':rangef0s})\n",
    "df_ques = pd.DataFrame({'maxf0s': maxf0s, 'minf0s':minf0s, 'rangef0s':rangef0s})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import svm\n",
    "from sklearn import dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dclf = DummyClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### following code, amend depending on whether it's 4-way, or lang, ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mandarin WH     0.287037\n",
       "English WH      0.285613\n",
       "Mandarin Y/N    0.216524\n",
       "English Y/N     0.210826\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels[\"labels\"].value_counts() /len(df_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2537207318451403"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores = cross_val_score(dclf, df_data, df_labels.values.squeeze(), cv=10)\n",
    "baseline_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachel\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some motherfuckin' GridSearching of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: grid_search is depreciating, will change to model_selection module\n",
    "#param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.svm import SVC\n",
    "grid_search = GridSearchCV(LinearSVC(), param_grid, cv=10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data, df_labels.values.squeeze(), random_state=0)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(penalty='l2', C=0.01, multi_class= \"ovr\")\n",
    "scores = cross_val_score(clf, df_data, df_labels.values.squeeze(), cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31039309493154865"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachel\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34472934472934474 ['English Y/N' 'English WH' 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH'\n",
      " 'English WH' 'English Y/N' 'English WH' 'Mandarin WH' 'English Y/N'\n",
      " 'Mandarin WH' 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'English Y/N' 'Mandarin WH' 'English WH' 'English Y/N' 'English WH'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'English WH' 'Mandarin Y/N' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'English WH' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'English WH' 'English Y/N' 'English WH' 'English WH' 'English Y/N'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'English WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N' 'English WH'\n",
      " 'English WH' 'Mandarin WH' 'English WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'English WH' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin WH' 'English WH' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin Y/N'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'English Y/N' 'English Y/N' 'English WH'\n",
      " 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'Mandarin Y/N' 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'English WH'\n",
      " 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'English WH' 'English Y/N' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'English Y/N' 'English WH' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'English Y/N' 'Mandarin Y/N' 'English WH'\n",
      " 'English WH' 'English WH' 'Mandarin Y/N' 'English Y/N' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'English WH' 'English WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'English WH' 'English WH' 'Mandarin WH'\n",
      " 'English WH' 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N' 'Mandarin Y/N' 'English WH'\n",
      " 'Mandarin WH' 'English Y/N' 'Mandarin WH' 'English Y/N' 'English WH'\n",
      " 'Mandarin WH' 'English WH' 'English WH' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English Y/N'\n",
      " 'Mandarin Y/N' 'Mandarin Y/N' 'English WH' 'Mandarin WH' 'English Y/N'\n",
      " 'English Y/N' 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH'\n",
      " 'English Y/N' 'Mandarin Y/N' 'Mandarin WH' 'English Y/N' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'English WH' 'English Y/N' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'Mandarin Y/N' 'English WH' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'English Y/N'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'English WH' 'Mandarin Y/N' 'Mandarin Y/N'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'English WH' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'English WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin Y/N' 'English Y/N' 'English WH' 'English WH'\n",
      " 'Mandarin WH' 'English Y/N' 'English WH' 'English Y/N' 'English WH'\n",
      " 'English WH' 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin Y/N'\n",
      " 'English WH' 'English WH' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'English WH' 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'English Y/N' 'Mandarin WH' 'English Y/N'\n",
      " 'Mandarin WH' 'English WH' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English Y/N'\n",
      " 'English Y/N' 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'English Y/N' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'English WH' 'English Y/N' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'English Y/N' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'Mandarin Y/N' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'English WH' 'English WH' 'Mandarin WH' 'English WH'\n",
      " 'English WH' 'Mandarin WH' 'English WH' 'English WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'English WH' 'English WH' 'Mandarin Y/N'\n",
      " 'English Y/N']\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data, df_labels, random_state=0)\n",
    "\n",
    "#logreg = LogisticRegression().fit(X_train, y_train)\n",
    "#score = logreg.score(X_test, y_test)\n",
    "\n",
    "#classifier = linear_model.LogisticRegression()\n",
    "classifier = svm.LinearSVC(penalty=\"l2\", C=0.01, multi_class='ovr')\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "predicts = classifier.predict(X_test)\n",
    "\n",
    "print (score, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mandarin WH' 'English Y/N' 'English Y/N' 'English Y/N' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'English WH' 'Mandarin WH' 'English WH'\n",
      " 'English WH' 'English Y/N' 'English Y/N' 'English WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'Mandarin Y/N' 'English WH' 'Mandarin WH'\n",
      " 'English Y/N' 'English Y/N' 'English Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'English WH'\n",
      " 'English Y/N' 'Mandarin Y/N' 'Mandarin WH' 'English Y/N' 'English WH'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin Y/N'\n",
      " 'English WH' 'English Y/N' 'Mandarin WH' 'English Y/N' 'English Y/N'\n",
      " 'English WH' 'English WH' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'English Y/N' 'English WH' 'Mandarin WH' 'Mandarin WH' 'English Y/N'\n",
      " 'Mandarin Y/N' 'English Y/N' 'Mandarin Y/N' 'English Y/N' 'English Y/N'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'English Y/N' 'English WH'\n",
      " 'English WH' 'English WH' 'English WH' 'English WH' 'Mandarin Y/N'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N' 'English Y/N'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'English WH' 'Mandarin WH' 'Mandarin Y/N'\n",
      " 'English Y/N' 'English Y/N' 'English WH' 'English WH' 'English WH'\n",
      " 'English WH' 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'English Y/N' 'English WH'\n",
      " 'English WH' 'English Y/N' 'English Y/N' 'Mandarin WH' 'Mandarin Y/N'\n",
      " 'English WH' 'Mandarin WH' 'English Y/N' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin WH' 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English Y/N' 'Mandarin WH' 'English WH' 'Mandarin Y/N' 'Mandarin Y/N'\n",
      " 'English Y/N' 'English WH' 'English WH' 'Mandarin Y/N' 'Mandarin Y/N'\n",
      " 'Mandarin WH' 'English WH' 'Mandarin WH' 'Mandarin Y/N' 'English Y/N'\n",
      " 'English Y/N' 'English WH' 'English WH' 'English Y/N' 'Mandarin Y/N'\n",
      " 'English WH' 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'English WH'\n",
      " 'English WH' 'English WH' 'Mandarin Y/N' 'English Y/N' 'English Y/N'\n",
      " 'English WH' 'Mandarin Y/N' 'Mandarin Y/N' 'English WH' 'Mandarin Y/N'\n",
      " 'Mandarin WH' 'Mandarin WH' 'English Y/N' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'English WH' 'English Y/N' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'English Y/N' 'Mandarin Y/N' 'English Y/N' 'Mandarin Y/N' 'English WH'\n",
      " 'English Y/N' 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin WH' 'English WH' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'English WH' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'English Y/N' 'Mandarin Y/N' 'English Y/N'\n",
      " 'Mandarin WH' 'English Y/N' 'English WH' 'English WH' 'English Y/N'\n",
      " 'English WH' 'English Y/N' 'English Y/N' 'English WH' 'Mandarin WH'\n",
      " 'English WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'English Y/N'\n",
      " 'English WH' 'English Y/N' 'English Y/N' 'English WH' 'Mandarin Y/N'\n",
      " 'English WH' 'English Y/N' 'Mandarin WH' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English WH' 'English WH' 'Mandarin Y/N' 'Mandarin Y/N' 'English WH'\n",
      " 'English Y/N' 'English WH' 'English WH' 'English WH' 'English WH'\n",
      " 'English WH' 'Mandarin Y/N' 'English Y/N' 'English Y/N' 'English WH'\n",
      " 'English WH' 'English Y/N' 'English Y/N' 'English WH' 'Mandarin WH'\n",
      " 'Mandarin Y/N' 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'English Y/N' 'English WH' 'Mandarin WH' 'English Y/N' 'English Y/N'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'English Y/N' 'English WH' 'Mandarin WH' 'English WH' 'Mandarin Y/N'\n",
      " 'Mandarin Y/N' 'English Y/N' 'Mandarin Y/N' 'Mandarin Y/N' 'Mandarin Y/N'\n",
      " 'English WH' 'Mandarin WH' 'English WH' 'English WH' 'Mandarin Y/N'\n",
      " 'Mandarin Y/N' 'English WH' 'English WH' 'Mandarin WH' 'Mandarin Y/N'\n",
      " 'Mandarin Y/N' 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'English WH' 'Mandarin WH' 'Mandarin WH' 'English Y/N'\n",
      " 'Mandarin WH' 'Mandarin WH' 'English Y/N' 'Mandarin WH' 'Mandarin Y/N'\n",
      " 'Mandarin WH' 'Mandarin Y/N' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'English Y/N' 'Mandarin WH' 'English Y/N' 'English WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'English WH' 'Mandarin Y/N' 'Mandarin Y/N'\n",
      " 'Mandarin Y/N' 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'Mandarin WH'\n",
      " 'Mandarin WH' 'English WH' 'Mandarin WH' 'Mandarin Y/N' 'English Y/N'\n",
      " 'Mandarin Y/N' 'English Y/N' 'Mandarin WH' 'English WH' 'Mandarin WH'\n",
      " 'English Y/N' 'English WH' 'Mandarin Y/N' 'Mandarin WH' 'English WH'\n",
      " 'Mandarin WH' 'Mandarin WH' 'Mandarin Y/N' 'English WH' 'English WH'\n",
      " 'English WH' 'English WH' 'English Y/N' 'English WH' 'Mandarin Y/N'\n",
      " 'English WH']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachel\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#### BETTER THAN CROSS VALIDATION DONE THE OTHER WAY ##########\n",
    "########## UPDATE PARAMATERS BASED ON ABOVE ##########\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data, df_labels, random_state=0)\n",
    "\n",
    "\n",
    "#classifier = DummyClassifier()\n",
    "#classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "dummy = DummyClassifier(strategy='stratified')\n",
    "\n",
    "X_converted, y_converted = check_X_y(X=X_test, y=y_test)\n",
    "dummy.fit(X=X_converted, y=y_converted)\n",
    "\n",
    "dummy_pred = dummy.predict(X_converted)\n",
    "\n",
    "\n",
    "#d_score = classifier.score(X_test, y_test)\n",
    "#d_predicts = classifier.predict(X_test)\n",
    "\n",
    "print (dummy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In which we do some math for significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_stand = list(df_labels[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gold_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicts = zip(dummy_pred, predicts, gold_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(all_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_wins:  95\n",
      "model_wins:  83\n"
     ]
    }
   ],
   "source": [
    "base_wins = 0\n",
    "model_wins = 0\n",
    "\n",
    "for(base, model, gold) in zip(dummy_pred, predicts, gold_stand):\n",
    "    if base == gold:\n",
    "        base_wins = base_wins+1\n",
    "    if model == gold:\n",
    "        model_wins = model_wins+1\n",
    "\n",
    "print(\"base_wins: \", base_wins)\n",
    "print(\"model_wins: \", model_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Kyle Gorman's code for McNemar's p values test ######\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mcnemar_p(b, c):\n",
    "  \"\"\"Computes McNemar's test.\n",
    "  Args:\n",
    "    b: the number of \"wins\" for the first condition.\n",
    "    c: the number of \"wins\" for the second condition.\n",
    "  Returns:\n",
    "    A p-value for McNemar's test.\n",
    "  \"\"\"\n",
    "  n = b + c\n",
    "  x = min(b, c)\n",
    "  dist = scipy.stats.binom(n, .5)\n",
    "  return 2. * dist.cdf(x)\n",
    "\n",
    "\n",
    "def mcnemar_midp(b, c):\n",
    "  \"\"\"Computes McNemar's test using the \"mid-p\" variant.\n",
    "  This is based closely on:\n",
    "    \n",
    "  M.W. Fagerland, S. Lydersen, P. Laake. 2013. The McNemar test for \n",
    "  binary matched-pairs data: Mid-p and asymptotic are better than exact \n",
    "  conditional. BMC Medical Research Methodology 13: 91.\n",
    "  Args:\n",
    "    b: the number of \"wins\" for the first condition.\n",
    "    c: the number of \"wins\" for the second condition.\n",
    "  Returns:\n",
    "    A p-value for the mid-p variant of McNemar's test.\n",
    "  \"\"\"\n",
    "  x = min(b, c)\n",
    "  dist = scipy.stats.binom(n, .5)\n",
    "  return mcnemar_p(b, c) - dist.pmf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4097360735808759"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = mcnemar_p(base_wins, model_wins)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratulations, your results are not at all significant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coeff['label'] = df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,5))\n",
    "df_coeff.groupby('label').mean().T.plot.bar(ax=ax1)\n",
    "df_coeff.groupby('label').std().T.plot.bar(ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "_ = df_coeff.boxplot(by = 'label', ax=ax, layout = (2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(nrows=2, ncols=4, figsize=(20,10))\n",
    "axlist = ax.flatten()\n",
    "for i, l in enumerate(df_coeff.columns[0:7]):\n",
    "    _ = sns.boxplot(x=\"label\", y=l, data=df_coeff, ax=axlist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
